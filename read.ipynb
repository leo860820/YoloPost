{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2460532-8c4c-4af1-ac2b-28f678244574",
   "metadata": {},
   "source": [
    "圖片來源:https://data.mendeley.com/datasets/7w7fccy7ky/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd83018b-8776-431e-a962-43dcb80f7967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 98.6ms\n",
      "Speed: 3.0ms preprocess, 98.6ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0000.png\n",
      "\n",
      "0: 448x640 1 person, 93.5ms\n",
      "Speed: 2.0ms preprocess, 93.5ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0002.png\n",
      "\n",
      "0: 448x640 1 person, 94.3ms\n",
      "Speed: 1.1ms preprocess, 94.3ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0004.png\n",
      "\n",
      "0: 448x640 2 persons, 95.4ms\n",
      "Speed: 1.0ms preprocess, 95.4ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 person, 98.8ms\n",
      "Speed: 3.0ms preprocess, 98.8ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0008.png\n",
      "\n",
      "0: 448x640 1 person, 99.0ms\n",
      "Speed: 2.0ms preprocess, 99.0ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0010.png\n",
      "\n",
      "0: 448x640 1 person, 108.2ms\n",
      "Speed: 1.0ms preprocess, 108.2ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0012.png\n",
      "\n",
      "0: 448x640 1 person, 97.1ms\n",
      "Speed: 1.0ms preprocess, 97.1ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0014.png\n",
      "\n",
      "0: 448x640 1 person, 96.9ms\n",
      "Speed: 1.1ms preprocess, 96.9ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0016.png\n",
      "\n",
      "0: 448x640 1 person, 96.0ms\n",
      "Speed: 2.0ms preprocess, 96.0ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0018.png\n",
      "\n",
      "0: 448x640 1 person, 97.9ms\n",
      "Speed: 1.0ms preprocess, 97.9ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0020.png\n",
      "\n",
      "0: 448x640 1 person, 96.9ms\n",
      "Speed: 1.0ms preprocess, 96.9ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0022.png\n",
      "\n",
      "0: 448x640 1 person, 98.2ms\n",
      "Speed: 2.0ms preprocess, 98.2ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0024.png\n",
      "\n",
      "0: 448x640 1 person, 99.5ms\n",
      "Speed: 1.0ms preprocess, 99.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0026.png\n",
      "\n",
      "0: 448x640 1 person, 98.2ms\n",
      "Speed: 1.1ms preprocess, 98.2ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0028.png\n",
      "\n",
      "0: 448x640 1 person, 97.2ms\n",
      "Speed: 1.0ms preprocess, 97.2ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0030.png\n",
      "\n",
      "0: 448x640 1 person, 96.1ms\n",
      "Speed: 1.0ms preprocess, 96.1ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0032.png\n",
      "\n",
      "0: 448x640 1 person, 99.4ms\n",
      "Speed: 1.0ms preprocess, 99.4ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0034.png\n",
      "\n",
      "0: 448x640 1 person, 96.0ms\n",
      "Speed: 2.0ms preprocess, 96.0ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0036.png\n",
      "\n",
      "0: 448x640 1 person, 95.9ms\n",
      "Speed: 2.0ms preprocess, 95.9ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0038.png\n",
      "\n",
      "0: 448x640 1 person, 95.0ms\n",
      "Speed: 2.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0040.png\n",
      "\n",
      "0: 448x640 1 person, 97.4ms\n",
      "Speed: 1.0ms preprocess, 97.4ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0042.png\n",
      "\n",
      "0: 448x640 1 person, 97.3ms\n",
      "Speed: 2.1ms preprocess, 97.3ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0044.png\n",
      "\n",
      "0: 448x640 1 person, 97.9ms\n",
      "Speed: 1.0ms preprocess, 97.9ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0046.png\n",
      "\n",
      "0: 448x640 1 person, 93.2ms\n",
      "Speed: 1.0ms preprocess, 93.2ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0048.png\n",
      "\n",
      "0: 448x640 1 person, 95.1ms\n",
      "Speed: 2.0ms preprocess, 95.1ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0050.png\n",
      "\n",
      "0: 448x640 1 person, 95.9ms\n",
      "Speed: 1.1ms preprocess, 95.9ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0052.png\n",
      "\n",
      "0: 448x640 1 person, 95.5ms\n",
      "Speed: 2.0ms preprocess, 95.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0054.png\n",
      "\n",
      "0: 448x640 1 person, 98.0ms\n",
      "Speed: 1.1ms preprocess, 98.0ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0056.png\n",
      "\n",
      "0: 448x640 1 person, 95.4ms\n",
      "Speed: 1.0ms preprocess, 95.4ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0058.png\n",
      "\n",
      "0: 448x640 1 person, 95.0ms\n",
      "Speed: 2.0ms preprocess, 95.0ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0060.png\n",
      "\n",
      "0: 448x640 1 person, 94.6ms\n",
      "Speed: 2.0ms preprocess, 94.6ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0062.png\n",
      "\n",
      "0: 448x640 1 person, 107.1ms\n",
      "Speed: 2.1ms preprocess, 107.1ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0064.png\n",
      "\n",
      "0: 448x640 1 person, 95.1ms\n",
      "Speed: 1.0ms preprocess, 95.1ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0066.png\n",
      "\n",
      "0: 448x640 1 person, 95.9ms\n",
      "Speed: 2.1ms preprocess, 95.9ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0068.png\n",
      "\n",
      "0: 448x640 1 person, 95.9ms\n",
      "Speed: 1.0ms preprocess, 95.9ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0070.png\n",
      "\n",
      "0: 448x640 1 person, 96.9ms\n",
      "Speed: 1.0ms preprocess, 96.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0072.png\n",
      "\n",
      "0: 448x640 1 person, 93.1ms\n",
      "Speed: 2.0ms preprocess, 93.1ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0074.png\n",
      "\n",
      "0: 448x640 1 person, 103.2ms\n",
      "Speed: 2.0ms preprocess, 103.2ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0076.png\n",
      "\n",
      "0: 448x640 1 person, 93.5ms\n",
      "Speed: 2.0ms preprocess, 93.5ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0078.png\n",
      "\n",
      "0: 448x640 1 person, 92.6ms\n",
      "Speed: 1.1ms preprocess, 92.6ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Processed and saved: C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.1/Fall forward_detect_0.3\\detected_0080.png\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 41\u001b[0m\n\u001b[0;32m     37\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(input_path)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# resized image to 640*640\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# resized_image = cv2.resize(image, (640, 640))\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Perform pose detection\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# Draw the results on the image\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     annotated_image \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\engine\\model.py:177\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    156\u001b[0m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    157\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    159\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    160\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m    An alias for the predict method, enabling the model instance to be callable.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m        (List[ultralytics.engine.results.Results]): A list of prediction results, encapsulated in the Results class.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source, stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\engine\\model.py:453\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\engine\\predictor.py:168\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\utils\\_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\engine\\predictor.py:254\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 254\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\engine\\predictor.py:142\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    137\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    138\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    141\u001b[0m )\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\nn\\autobackend.py:455\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 455\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\nn\\tasks.py:89\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\nn\\tasks.py:107\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\nn\\tasks.py:128\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 128\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    129\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:230\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    229\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 230\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:230\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    229\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 230\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:340\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    339\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"'forward()' applies the YOLO FPN to input data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:54\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import csv\n",
    "conf = 0.3\n",
    "s = 1\n",
    "dir = \"Fall forward\"\n",
    "# Path to the directory containing images\n",
    "input_dir = f'C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.{s}/{dir}' # 存放image資料夾\n",
    "output_dir = f'C:/Users/User/Desktop/Dataset CAUCAFall/CAUCAFall/Subject.{s}/{dir}_detect_{conf}' # 偵測後輸出image 資料夾\n",
    "output_file = f\"C:/Users/User/Desktop/Dataset CAUCAFall/keypoints_data_s{s}_{dir}_{conf}.csv\" # image keypoint csv\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load YOLOv8 model for pose detection\n",
    "model = YOLO('yolov8n-pose.pt')  # Ensure you have the correct YOLOv8 pose model\n",
    "def process_image(results):\n",
    "    r = results[0]\n",
    "    combined_results = []\n",
    "    for i in range(len(r.keypoints.xyn)):\n",
    "        for  j  in range(17):\n",
    "            x, y = r.keypoints.xyn[i][j].numpy()\n",
    "            confidence = r.keypoints.conf[i][j].item()  # Convert tensor to float\n",
    "            combined_results.append((x, y, confidence))\n",
    "    return combined_results\n",
    "# Process each JPG image in the input directory\n",
    "all_keypoints_data = []\n",
    "for idx, filename in enumerate(os.listdir(input_dir)):\n",
    "    if filename.lower().endswith('.png'):\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        \n",
    "        # New filename with renaming convention, e.g., prefix \"detected_\" + original filename\n",
    "        new_filename = f'detected_{idx:04d}.png'  # e.g., detected_0001.jpg, detected_0002.jpg, etc.\n",
    "        output_path = os.path.join(output_dir, new_filename)\n",
    "\n",
    "        # Load the image\n",
    "        image = cv2.imread(input_path)\n",
    "        # resized image to 640*640\n",
    "        # resized_image = cv2.resize(image, (640, 640))\n",
    "        # Perform pose detection\n",
    "        results = model(image, conf=conf)\n",
    "\n",
    "        if len(results[0].boxes) == 1:\n",
    "            # Draw the results on the image\n",
    "            annotated_image = results[0].plot()\n",
    "            # Save the annotated image with the new filename\n",
    "            cv2.imwrite(output_path, annotated_image)\n",
    "            print(f\"Processed and saved: {output_path}\")\n",
    "            keypoints_data = process_image(results)\n",
    "            keypoints_data.insert(0, new_filename)\n",
    "            all_keypoints_data.append(keypoints_data)\n",
    "            \n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    \n",
    "    # Write the header\n",
    "    header = [\"image_name\"] + [f\"x{i+1}, y{i+1}, confidence{i+1}\" for i in range(len(all_keypoints_data[0]) - 1)]\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    # Write the data\n",
    "    writer.writerows(all_keypoints_data)\n",
    "\n",
    "print(\"Data saved to\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6723a225-07a5-4b0d-86cc-75f30d9a08e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             image_name        x1, y1, confidence1      x2, y2, confidence2  \\\n",
      "0     detected_0000.png                 (0.0, 0.0)               (0.0, 0.0)   \n",
      "1     detected_0002.png                 (0.0, 0.0)               (0.0, 0.0)   \n",
      "2     detected_0004.png                 (0.0, 0.0)               (0.0, 0.0)   \n",
      "3     detected_0006.png                 (0.0, 0.0)               (0.0, 0.0)   \n",
      "4     detected_0008.png                 (0.0, 0.0)               (0.0, 0.0)   \n",
      "...                 ...                        ...                      ...   \n",
      "1628  detected_0472.png   (0.55212075, 0.07922764)  (0.5568776, 0.06957651)   \n",
      "1629  detected_0474.png    (0.5495374, 0.07559716)  (0.5553281, 0.06585138)   \n",
      "1630  detected_0476.png    (0.5505092, 0.07821099)  (0.5555378, 0.06897019)   \n",
      "1631  detected_0478.png  (0.54478145, 0.074853435)  (0.5509016, 0.06510606)   \n",
      "1632  detected_0480.png   (0.54442215, 0.07527539)  (0.550184, 0.065937564)   \n",
      "\n",
      "           x3, y3, confidence3        x4, y4, confidence4  \\\n",
      "0                   (0.0, 0.0)    (0.23288156, 0.2911118)   \n",
      "1                   (0.0, 0.0)   (0.23467308, 0.28417584)   \n",
      "2                   (0.0, 0.0)   (0.23559399, 0.28077325)   \n",
      "3                   (0.0, 0.0)   (0.24238992, 0.27923238)   \n",
      "4                   (0.0, 0.0)    (0.25602853, 0.2679854)   \n",
      "...                        ...                        ...   \n",
      "1628   (0.5463916, 0.07035766)  (0.56547743, 0.062154792)   \n",
      "1629   (0.5432877, 0.06674331)    (0.5655731, 0.06023992)   \n",
      "1630  (0.5449752, 0.068991505)  (0.56438744, 0.065202095)   \n",
      "1631   (0.5385016, 0.06586382)   (0.5618263, 0.059581783)   \n",
      "1632   (0.5381504, 0.06675566)  (0.56020695, 0.061085694)   \n",
      "\n",
      "            x5, y5, confidence5       x6, y6, confidence6  \\\n",
      "0                    (0.0, 0.0)  (0.24753892, 0.36143857)   \n",
      "1                    (0.0, 0.0)  (0.24413489, 0.36059743)   \n",
      "2                    (0.0, 0.0)  (0.24650063, 0.36624926)   \n",
      "3                    (0.0, 0.0)  (0.24988627, 0.36803994)   \n",
      "4       (0.2877817, 0.25337276)   (0.25331515, 0.3592337)   \n",
      "...                         ...                       ...   \n",
      "1628  (0.53778905, 0.063699864)   (0.5821496, 0.10304881)   \n",
      "1629   (0.53464264, 0.06202695)   (0.5811408, 0.10392885)   \n",
      "1630                 (0.0, 0.0)  (0.58211863, 0.10516097)   \n",
      "1631    (0.5300157, 0.06109213)  (0.57783574, 0.10392914)   \n",
      "1632    (0.5293728, 0.06326375)   (0.5760264, 0.10551461)   \n",
      "\n",
      "           x7, y7, confidence7       x8, y8, confidence8  \\\n",
      "0      (0.3117138, 0.30932587)  (0.24587075, 0.47934428)   \n",
      "1     (0.31360182, 0.31231153)  (0.24139076, 0.47751966)   \n",
      "2     (0.31982028, 0.31878835)  (0.23719668, 0.48641104)   \n",
      "3      (0.3234948, 0.32046285)  (0.23849037, 0.48632854)   \n",
      "4      (0.32446602, 0.3229645)  (0.24091725, 0.47102875)   \n",
      "...                        ...                       ...   \n",
      "1628  (0.5252384, 0.101801716)   (0.6016067, 0.17387608)   \n",
      "1629  (0.5237956, 0.103195764)   (0.6010605, 0.17307085)   \n",
      "1630   (0.5210645, 0.10576851)  (0.59865636, 0.16946395)   \n",
      "1631  (0.51940924, 0.10331996)   (0.5976548, 0.17489348)   \n",
      "1632  (0.51825106, 0.10691191)     (0.5955289, 0.176198)   \n",
      "\n",
      "           x9, y9, confidence9    x10, y10, confidence10  \\\n",
      "0     (0.35076293, 0.38649213)  (0.24767834, 0.54722655)   \n",
      "1     (0.35363692, 0.39086294)   (0.24895649, 0.5461843)   \n",
      "2      (0.3552843, 0.39376953)   (0.24637127, 0.5429314)   \n",
      "3     (0.35764727, 0.39468262)   (0.2541622, 0.52852756)   \n",
      "4     (0.36831602, 0.41178694)   (0.2662041, 0.49228626)   \n",
      "...                        ...                       ...   \n",
      "1628     (0.508796, 0.1677913)   (0.60178596, 0.2349804)   \n",
      "1629   (0.5070907, 0.16803813)    (0.602736, 0.23091927)   \n",
      "1630  (0.50997096, 0.16863894)  (0.60098654, 0.23401383)   \n",
      "1631   (0.5037271, 0.16903855)  (0.59940946, 0.23808745)   \n",
      "1632   (0.5030608, 0.17316784)   (0.59828997, 0.2440204)   \n",
      "\n",
      "        x11, y11, confidence11    x12, y12, confidence12  \\\n",
      "0     (0.32998475, 0.46833184)  (0.31367058, 0.52798575)   \n",
      "1       (0.3316386, 0.4680968)   (0.3109158, 0.52639186)   \n",
      "2      (0.34398025, 0.4642221)   (0.30947235, 0.5345761)   \n",
      "3        (0.350829, 0.4690185)    (0.30556127, 0.533619)   \n",
      "4     (0.36025387, 0.47070533)   (0.30754852, 0.5231247)   \n",
      "...                        ...                       ...   \n",
      "1628    (0.5074073, 0.2314699)  (0.57175165, 0.23444529)   \n",
      "1629   (0.50722986, 0.2292277)   (0.5700442, 0.23258549)   \n",
      "1630  (0.50829613, 0.22670533)  (0.57191443, 0.23187065)   \n",
      "1631   (0.5060875, 0.22853154)   (0.5681382, 0.23229048)   \n",
      "1632  (0.50625604, 0.23102102)   (0.5675321, 0.23297296)   \n",
      "\n",
      "        x13, y13, confidence13    x14, y14, confidence14  \\\n",
      "0       (0.35650727, 0.506506)   (0.3269688, 0.64723396)   \n",
      "1       (0.3571222, 0.5067806)    (0.3261711, 0.6449606)   \n",
      "2       (0.3570922, 0.5135805)   (0.3255149, 0.64766526)   \n",
      "3      (0.35453862, 0.5129034)   (0.32900426, 0.6455195)   \n",
      "4     (0.35567746, 0.51221484)  (0.33447185, 0.64138854)   \n",
      "...                        ...                       ...   \n",
      "1628   (0.5354139, 0.23317647)   (0.5698803, 0.32437542)   \n",
      "1629    (0.5334936, 0.2316805)   (0.56925917, 0.3229146)   \n",
      "1630  (0.53342664, 0.23219791)    (0.5723118, 0.3198743)   \n",
      "1631   (0.5308188, 0.23160043)    (0.5686376, 0.3239318)   \n",
      "1632  (0.53027934, 0.23301874)   (0.56899667, 0.3239602)   \n",
      "\n",
      "        x15, y15, confidence15    x16, y16, confidence16  \\\n",
      "0      (0.35961604, 0.5984466)   (0.35690913, 0.7497779)   \n",
      "1       (0.3618758, 0.5983182)    (0.3546629, 0.7499989)   \n",
      "2      (0.37188202, 0.5974459)  (0.35807607, 0.74749166)   \n",
      "3      (0.38081062, 0.5926929)   (0.36026073, 0.7440988)   \n",
      "4     (0.37677333, 0.60878086)   (0.37448934, 0.7398968)   \n",
      "...                        ...                       ...   \n",
      "1628   (0.5329912, 0.32174644)   (0.5647415, 0.40950394)   \n",
      "1629   (0.5324043, 0.32104206)    (0.565049, 0.40804273)   \n",
      "1630   (0.5321437, 0.31961793)   (0.5666339, 0.40061465)   \n",
      "1631   (0.5298024, 0.32201165)  (0.56523323, 0.40855235)   \n",
      "1632  (0.52899146, 0.32214543)  (0.56771386, 0.40932712)   \n",
      "\n",
      "        x17, y17, confidence17  label  \n",
      "0       (0.39563903, 0.694425)      0  \n",
      "1       (0.40177003, 0.697664)      0  \n",
      "2     (0.40616524, 0.69086957)      0  \n",
      "3     (0.41388404, 0.68455416)      0  \n",
      "4       (0.41638628, 0.704132)      0  \n",
      "...                        ...    ...  \n",
      "1628    (0.5330961, 0.4064034)      0  \n",
      "1629  (0.53388065, 0.40614188)      0  \n",
      "1630  (0.53222877, 0.39968586)      0  \n",
      "1631    (0.532541, 0.40625715)      0  \n",
      "1632   (0.53151125, 0.4070638)      0  \n",
      "\n",
      "[1633 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory containing the CSV files\n",
    "directory = 'C:/Users/User/Desktop/fallexcel/Subject.4'\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Filter the list to include only CSV files\n",
    "csv_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Read each CSV file into a DataFrame and append it to the list\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames along axis 0\n",
    "combined_df = pd.concat(dataframes, axis=0)\n",
    "\n",
    "# Reset the index of the combined DataFrame\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(combined_df)\n",
    "\n",
    "# Specify the path for the output CSV file\n",
    "output_file = 'C:/Users/User/Desktop/fallexcel/combined_Subject_4.csv'\n",
    "\n",
    "# Export the combined DataFrame to a CSV file\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
