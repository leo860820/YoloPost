{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57daebd6-c47d-4f83-aad9-92480cb0beb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "import ast\n",
    "from keras.utils import to_categorical\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad35cf77-8da5-4f97-9a36-4db2e449fd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\DL\\lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2580 - accuracy: 0.9081 - val_loss: 0.1312 - val_accuracy: 0.9457\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1008 - accuracy: 0.9644 - val_loss: 0.0720 - val_accuracy: 0.9793\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.9773 - val_loss: 0.0638 - val_accuracy: 0.9780\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.9806 - val_loss: 0.0617 - val_accuracy: 0.9780\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9815 - val_loss: 0.0762 - val_accuracy: 0.9793\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0482 - accuracy: 0.9825 - val_loss: 0.0719 - val_accuracy: 0.9780\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9861 - val_loss: 0.0872 - val_accuracy: 0.9793\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0416 - accuracy: 0.9851 - val_loss: 0.0623 - val_accuracy: 0.9832\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0523 - accuracy: 0.9815 - val_loss: 0.0864 - val_accuracy: 0.9715\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.9832 - val_loss: 0.0584 - val_accuracy: 0.9858\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 0.9880 - val_loss: 0.0708 - val_accuracy: 0.9845\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9906 - val_loss: 0.0765 - val_accuracy: 0.9845\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0528 - accuracy: 0.9832 - val_loss: 0.0631 - val_accuracy: 0.9897\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0328 - accuracy: 0.9906 - val_loss: 0.0635 - val_accuracy: 0.9858\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.9929 - val_loss: 0.0636 - val_accuracy: 0.9897\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 0.9916 - val_loss: 0.0638 - val_accuracy: 0.9845\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 0.9861 - val_loss: 0.0640 - val_accuracy: 0.9832\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 0.9913 - val_loss: 0.0830 - val_accuracy: 0.9897\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.9929 - val_loss: 0.1374 - val_accuracy: 0.9806\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9909 - val_loss: 0.0706 - val_accuracy: 0.9884\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 0.9900 - val_loss: 0.0661 - val_accuracy: 0.9871\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 0.9935 - val_loss: 0.0748 - val_accuracy: 0.9871\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.0830 - val_accuracy: 0.9858\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9958 - val_loss: 0.1023 - val_accuracy: 0.9819\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 0.0736 - val_accuracy: 0.9845\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 0.9929 - val_loss: 0.0797 - val_accuracy: 0.9871\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9938 - val_loss: 0.1065 - val_accuracy: 0.9832\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9900 - val_loss: 0.0625 - val_accuracy: 0.9858\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 0.1065 - val_accuracy: 0.9832\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 0.9926 - val_loss: 0.0948 - val_accuracy: 0.9858\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9971 - val_loss: 0.1311 - val_accuracy: 0.9806\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0225 - accuracy: 0.9935 - val_loss: 0.0864 - val_accuracy: 0.9806\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9955 - val_loss: 0.0753 - val_accuracy: 0.9858\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.0860 - val_accuracy: 0.9832\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0859 - val_accuracy: 0.9845\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9935 - val_loss: 0.0862 - val_accuracy: 0.9832\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9942 - val_loss: 0.0757 - val_accuracy: 0.9858\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.0909 - val_accuracy: 0.9858\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9929 - val_loss: 0.1219 - val_accuracy: 0.9702\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9942 - val_loss: 0.0794 - val_accuracy: 0.9858\n",
      "Epoch 41/100\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "version = '1'\n",
    "dataset = pd.read_csv(f'C:/Users/User/Desktop/sum{version}.csv')\n",
    "dataset = dataset.drop(dataset.columns[0], axis=1)\n",
    "# Function to convert string coordinates to tuple of floats\n",
    "def convert_coordinates(coord_string):\n",
    "    # Remove parentheses and split by comma\n",
    "    coords = coord_string.strip('()').split(',')\n",
    "    # Convert each coordinate to float\n",
    "    return tuple(float(coord) for coord in coords)\n",
    "\n",
    "# Convert coordinates columns from string to tuple of floats\n",
    "for col in dataset.columns[:-1]:  # Exclude the last column (labels)\n",
    "    dataset[col] = dataset[col].apply(convert_coordinates)\n",
    "\n",
    "# Extract features (coordinates) and labels (classes)\n",
    "X = dataset.iloc[:, :-1].values  # Features: all columns except the last one\n",
    "y = dataset.iloc[:, -1].values   # Labels: the last column\n",
    "# Determine number of classes\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# Convert labels to categorical format (required for multi-class classification)\n",
    "y = to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Flatten the coordinate pairs for MLP input (assuming 17 pairs per row)\n",
    "X_train_flat = np.array([pair for row in X_train for pair in row]).reshape(len(X_train), -1)\n",
    "X_test_flat = np.array([pair for row in X_test for pair in row]).reshape(len(X_test), -1)\n",
    "# Standardize the features (optional but recommended for MLPs)\n",
    "scaler = StandardScaler()\n",
    "X_train_flat = scaler.fit_transform(X_train_flat)\n",
    "X_test_flat = scaler.transform(X_test_flat)\n",
    "\n",
    "# # Define the MLP model using Keras Sequential API\n",
    "# model = Sequential()\n",
    "# model.add(Dense(256, input_dim=X_train_flat.shape[1], activation='relu'))\n",
    "# for _ in range(100):\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "model = Sequential([\n",
    "    Dense(256, input_dim=X_train_flat.shape[1], activation='relu'),  # Input layer with 64 units and ReLU activation\n",
    "    Dense(256, activation='relu'),                                 # Hidden layer with 64 units and ReLU activation\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001),\n",
    "              loss='categorical_crossentropy',   # Use categorical crossentropy for multi-class classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_flat, y_train, epochs=100, batch_size=100, validation_data=(X_test_flat, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef9f6da5-3934-4393-8a8e-0fc7869055b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1776 - accuracy: 0.9780\n",
      "Loss: 0.1776, Accuracy: 0.9780\n",
      "25/25 [==============================] - 0s 1ms/step\n",
      "Confusion Matrix:\n",
      "[[408  10]\n",
      " [  7 348]]\n",
      "\n",
      "Accuracy: 0.9780077619663649\n",
      "Precision: 0.9720670391061452\n",
      "Recall: 0.9802816901408451\n",
      "F1 Score: 0.9761570827489481\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming 'model' is your trained MLP model and 'scaler' is your trained scaler\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_flat, y_test)\n",
    "print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Save the model and scaler\n",
    "model.save(f'new_mlp_model_{version}.h5')\n",
    "joblib.dump(scaler, f'new_mlp_scaler_{version}.pkl')\n",
    "\n",
    "# Predict probabilities for X_test_flat\n",
    "y_pred_prob = model.predict(X_test_flat)\n",
    "# Convert probabilities to class predictions\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "# Ensure y_test is in the correct format (1D array)\n",
    "if y_test.ndim > 1:\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Assuming y_test and y_pred are already defined\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nAccuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
