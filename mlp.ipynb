{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57daebd6-c47d-4f83-aad9-92480cb0beb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "import ast\n",
    "from keras.utils import to_categorical\n",
    "import joblib\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad35cf77-8da5-4f97-9a36-4db2e449fd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\DL\\lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 1s 4ms/step - loss: 0.1187 - accuracy: 0.9597 - val_loss: 0.0923 - val_accuracy: 0.9752\n",
      "Epoch 2/100\n",
      "184/184 [==============================] - 1s 3ms/step - loss: 0.0743 - accuracy: 0.9779 - val_loss: 0.0621 - val_accuracy: 0.9798\n",
      "Epoch 3/100\n",
      "184/184 [==============================] - 1s 3ms/step - loss: 0.0637 - accuracy: 0.9796 - val_loss: 0.0659 - val_accuracy: 0.9804\n",
      "Epoch 4/100\n",
      "184/184 [==============================] - 1s 3ms/step - loss: 0.0539 - accuracy: 0.9836 - val_loss: 0.0652 - val_accuracy: 0.9822\n",
      "Epoch 5/100\n",
      "184/184 [==============================] - 1s 3ms/step - loss: 0.0471 - accuracy: 0.9856 - val_loss: 0.0489 - val_accuracy: 0.9846\n",
      "Epoch 6/100\n",
      "184/184 [==============================] - 1s 3ms/step - loss: 0.0440 - accuracy: 0.9859 - val_loss: 0.0443 - val_accuracy: 0.9859\n",
      "Epoch 7/100\n",
      "184/184 [==============================] - 1s 5ms/step - loss: 0.0393 - accuracy: 0.9875 - val_loss: 0.0437 - val_accuracy: 0.9841\n",
      "Epoch 8/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0362 - accuracy: 0.9882 - val_loss: 0.0477 - val_accuracy: 0.9872\n",
      "Epoch 9/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0341 - accuracy: 0.9894 - val_loss: 0.0500 - val_accuracy: 0.9861\n",
      "Epoch 10/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0378 - accuracy: 0.9877 - val_loss: 0.0624 - val_accuracy: 0.9809\n",
      "Epoch 11/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0334 - accuracy: 0.9900 - val_loss: 0.0378 - val_accuracy: 0.9885\n",
      "Epoch 12/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0300 - accuracy: 0.9898 - val_loss: 0.0400 - val_accuracy: 0.9880\n",
      "Epoch 13/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0283 - accuracy: 0.9909 - val_loss: 0.0478 - val_accuracy: 0.9874\n",
      "Epoch 14/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.0544 - val_accuracy: 0.9904\n",
      "Epoch 15/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.0481 - val_accuracy: 0.9865\n",
      "Epoch 16/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0286 - accuracy: 0.9913 - val_loss: 0.0354 - val_accuracy: 0.9909\n",
      "Epoch 17/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 0.0404 - val_accuracy: 0.9893\n",
      "Epoch 18/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 0.0373 - val_accuracy: 0.9906\n",
      "Epoch 19/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.0387 - val_accuracy: 0.9930\n",
      "Epoch 20/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.0379 - val_accuracy: 0.9920\n",
      "Epoch 21/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.0536 - val_accuracy: 0.9913\n",
      "Epoch 22/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0197 - accuracy: 0.9931 - val_loss: 0.0593 - val_accuracy: 0.9809\n",
      "Epoch 23/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.0471 - val_accuracy: 0.9904\n",
      "Epoch 24/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.0276 - val_accuracy: 0.9930\n",
      "Epoch 25/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.0529 - val_accuracy: 0.9872\n",
      "Epoch 26/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0477 - val_accuracy: 0.9911\n",
      "Epoch 27/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0163 - accuracy: 0.9955 - val_loss: 0.0492 - val_accuracy: 0.9913\n",
      "Epoch 28/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.0338 - val_accuracy: 0.9928\n",
      "Epoch 29/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.0368 - val_accuracy: 0.9926\n",
      "Epoch 30/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.0371 - val_accuracy: 0.9930\n",
      "Epoch 31/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.0362 - val_accuracy: 0.9922\n",
      "Epoch 32/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.0278 - val_accuracy: 0.9941\n",
      "Epoch 33/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 0.0478 - val_accuracy: 0.9913\n",
      "Epoch 34/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.0427 - val_accuracy: 0.9896\n",
      "Epoch 35/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0090 - accuracy: 0.9967 - val_loss: 0.0818 - val_accuracy: 0.9880\n",
      "Epoch 36/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.0496 - val_accuracy: 0.9874\n",
      "Epoch 37/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0164 - accuracy: 0.9955 - val_loss: 0.0390 - val_accuracy: 0.9957\n",
      "Epoch 38/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0072 - accuracy: 0.9973 - val_loss: 0.0364 - val_accuracy: 0.9933\n",
      "Epoch 39/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.0319 - val_accuracy: 0.9939\n",
      "Epoch 40/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.0393 - val_accuracy: 0.9937\n",
      "Epoch 41/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.0347 - val_accuracy: 0.9930\n",
      "Epoch 42/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.0341 - val_accuracy: 0.9952\n",
      "Epoch 43/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.0301 - val_accuracy: 0.9933\n",
      "Epoch 44/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 0.0325 - val_accuracy: 0.9937\n",
      "Epoch 45/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.0526 - val_accuracy: 0.9943\n",
      "Epoch 46/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.0747 - val_accuracy: 0.9935\n",
      "Epoch 47/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 0.0266 - val_accuracy: 0.9954\n",
      "Epoch 48/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0474 - val_accuracy: 0.9935\n",
      "Epoch 49/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.0295 - val_accuracy: 0.9948\n",
      "Epoch 50/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 0.0491 - val_accuracy: 0.9943\n",
      "Epoch 51/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 0.1068 - val_accuracy: 0.9941\n",
      "Epoch 52/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0250 - accuracy: 0.9942 - val_loss: 0.0448 - val_accuracy: 0.9902\n",
      "Epoch 53/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.0521 - val_accuracy: 0.9943\n",
      "Epoch 54/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.0591 - val_accuracy: 0.9941\n",
      "Epoch 55/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.0365 - val_accuracy: 0.9926\n",
      "Epoch 56/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0309 - val_accuracy: 0.9928\n",
      "Epoch 57/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0072 - accuracy: 0.9972 - val_loss: 0.0330 - val_accuracy: 0.9943\n",
      "Epoch 58/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.0413 - val_accuracy: 0.9941\n",
      "Epoch 59/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.0298 - val_accuracy: 0.9952\n",
      "Epoch 60/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0543 - val_accuracy: 0.9948\n",
      "Epoch 61/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.0618 - val_accuracy: 0.9952\n",
      "Epoch 62/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.0422 - val_accuracy: 0.9950\n",
      "Epoch 63/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0591 - val_accuracy: 0.9937\n",
      "Epoch 64/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.0522 - val_accuracy: 0.9948\n",
      "Epoch 65/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.0374 - val_accuracy: 0.9920\n",
      "Epoch 66/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.0276 - val_accuracy: 0.9930\n",
      "Epoch 67/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.0929 - val_accuracy: 0.9946\n",
      "Epoch 68/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0839 - val_accuracy: 0.9939\n",
      "Epoch 69/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0105 - accuracy: 0.9973 - val_loss: 0.0358 - val_accuracy: 0.9926\n",
      "Epoch 70/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0160 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9909\n",
      "Epoch 71/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 0.0342 - val_accuracy: 0.9939\n",
      "Epoch 72/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0485 - val_accuracy: 0.9889\n",
      "Epoch 73/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.0318 - val_accuracy: 0.9954\n",
      "Epoch 74/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0411 - val_accuracy: 0.9937\n",
      "Epoch 75/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.0526 - val_accuracy: 0.9930\n",
      "Epoch 76/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.0470 - val_accuracy: 0.9941\n",
      "Epoch 77/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.0585 - val_accuracy: 0.9948\n",
      "Epoch 78/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0849 - val_accuracy: 0.9937\n",
      "Epoch 79/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0133 - accuracy: 0.9965 - val_loss: 0.0356 - val_accuracy: 0.9939\n",
      "Epoch 80/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.0567 - val_accuracy: 0.9920\n",
      "Epoch 81/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0131 - accuracy: 0.9972 - val_loss: 0.0487 - val_accuracy: 0.9939\n",
      "Epoch 82/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.0563 - val_accuracy: 0.9948\n",
      "Epoch 83/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.1021 - val_accuracy: 0.9939\n",
      "Epoch 84/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.1021 - val_accuracy: 0.9935\n",
      "Epoch 85/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0160 - accuracy: 0.9966 - val_loss: 0.0686 - val_accuracy: 0.9900\n",
      "Epoch 86/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.0597 - val_accuracy: 0.9928\n",
      "Epoch 87/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0577 - val_accuracy: 0.9930\n",
      "Epoch 88/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.1240 - val_accuracy: 0.9900\n",
      "Epoch 89/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.0437 - val_accuracy: 0.9935\n",
      "Epoch 90/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0886 - val_accuracy: 0.9943\n",
      "Epoch 91/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.0444 - val_accuracy: 0.9920\n",
      "Epoch 92/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.0508 - val_accuracy: 0.9946\n",
      "Epoch 93/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0529 - val_accuracy: 0.9952\n",
      "Epoch 94/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0458 - val_accuracy: 0.9950\n",
      "Epoch 95/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0123 - accuracy: 0.9971 - val_loss: 0.0544 - val_accuracy: 0.9922\n",
      "Epoch 96/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0112 - accuracy: 0.9977 - val_loss: 0.0539 - val_accuracy: 0.9941\n",
      "Epoch 97/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.0870 - val_accuracy: 0.9939\n",
      "Epoch 98/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0148 - accuracy: 0.9960 - val_loss: 0.0565 - val_accuracy: 0.9943\n",
      "Epoch 99/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0564 - val_accuracy: 0.9928\n",
      "Epoch 100/100\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0434 - val_accuracy: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1da79f79bb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version = '4'\n",
    "dataset = pd.read_csv(f'C:/Users/User/Desktop/yolofall/sum{version}.csv')\n",
    "dataset = dataset.drop(dataset.columns[0], axis=1)\n",
    "# Function to convert string coordinates to tuple of floats\n",
    "def convert_coordinates(coord_string):\n",
    "    # Remove parentheses and split by comma\n",
    "    coords = coord_string.strip('()').split(',')\n",
    "    # Convert each coordinate to float\n",
    "    return tuple(float(coord) for coord in coords)\n",
    "\n",
    "# Convert coordinates columns from string to tuple of floats\n",
    "for col in dataset.columns[:-1]:  # Exclude the last column (labels)\n",
    "    dataset[col] = dataset[col].apply(convert_coordinates)\n",
    "\n",
    "# Extract features (coordinates) and labels (classes)\n",
    "X = dataset.iloc[:, :-1].values  # Features: all columns except the last one\n",
    "y = dataset.iloc[:, -1].values   # Labels: the last column\n",
    "# Apply random oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X, y = ros.fit_resample(X, y)\n",
    "# Determine number of classes\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# Convert labels to categorical format (required for multi-class classification)\n",
    "y = to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Flatten the coordinate pairs for MLP input (assuming 17 pairs per row)\n",
    "X_train_flat = np.array([pair for row in X_train for pair in row]).reshape(len(X_train), -1)\n",
    "X_test_flat = np.array([pair for row in X_test for pair in row]).reshape(len(X_test), -1)\n",
    "# Standardize the features (optional but recommended for MLPs)\n",
    "scaler = StandardScaler()\n",
    "X_train_flat = scaler.fit_transform(X_train_flat)\n",
    "X_test_flat = scaler.transform(X_test_flat)\n",
    "\n",
    "# # Define the MLP model using Keras Sequential API\n",
    "# model = Sequential()\n",
    "# model.add(Dense(256, input_dim=X_train_flat.shape[1], activation='relu'))\n",
    "# for _ in range(100):\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "model = Sequential([\n",
    "    Dense(256, input_dim=X_train_flat.shape[1], activation='relu'),  # Input layer with 64 units and ReLU activation\n",
    "    Dense(256, activation='relu'),                                 # Hidden layer with 64 units and ReLU activation\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001),\n",
    "              loss='categorical_crossentropy',   # Use categorical crossentropy for multi-class classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_flat, y_train, epochs=100, batch_size=100, validation_data=(X_test_flat, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef9f6da5-3934-4393-8a8e-0fc7869055b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0434 - accuracy: 0.9922\n",
      "Loss: 0.0434, Accuracy: 0.9922\n",
      "144/144 [==============================] - 0s 1ms/step\n",
      "Confusion Matrix:\n",
      "[[2336    4]\n",
      " [  32 2226]]\n",
      "\n",
      "Accuracy: 0.9921705089169204\n",
      "Precision: 0.9982062780269059\n",
      "Recall: 0.9858281665190434\n",
      "F1 Score: 0.9919786096256684\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming 'model' is your trained MLP model and 'scaler' is your trained scaler\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_flat, y_test)\n",
    "print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Save the model and scaler\n",
    "model.save(f'new_mlp_model_{version}.h5')\n",
    "joblib.dump(scaler, f'new_mlp_scaler_{version}.pkl')\n",
    "\n",
    "# Predict probabilities for X_test_flat\n",
    "y_pred_prob = model.predict(X_test_flat)\n",
    "# Convert probabilities to class predictions\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "# Ensure y_test is in the correct format (1D array)\n",
    "if y_test.ndim > 1:\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Assuming y_test and y_pred are already defined\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nAccuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
