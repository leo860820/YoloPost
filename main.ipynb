{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d06fd2e-7ffd-47af-9879-86981e231768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 197.6ms\n",
      "Speed: 3.0ms preprocess, 197.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.3ms\n",
      "Speed: 2.0ms preprocess, 84.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.5ms\n",
      "Speed: 1.0ms preprocess, 82.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.8ms\n",
      "Speed: 1.1ms preprocess, 80.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.3ms\n",
      "Speed: 1.0ms preprocess, 81.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.0ms\n",
      "Speed: 1.0ms preprocess, 81.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 91.6ms\n",
      "Speed: 1.0ms preprocess, 91.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.3ms\n",
      "Speed: 1.0ms preprocess, 84.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.6ms\n",
      "Speed: 2.0ms preprocess, 80.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.2ms\n",
      "Speed: 1.0ms preprocess, 81.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 89.7ms\n",
      "Speed: 2.0ms preprocess, 89.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.8ms\n",
      "Speed: 1.9ms preprocess, 85.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.2ms\n",
      "Speed: 1.0ms preprocess, 83.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.7ms\n",
      "Speed: 1.1ms preprocess, 81.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.3ms\n",
      "Speed: 1.0ms preprocess, 82.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 79.7ms\n",
      "Speed: 1.0ms preprocess, 79.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.6ms\n",
      "Speed: 1.0ms preprocess, 81.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.3ms\n",
      "Speed: 1.0ms preprocess, 81.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.5ms\n",
      "Speed: 1.0ms preprocess, 81.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import joblib\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import requests\n",
    "model = YOLO(\"yolov8n-pose.pt\")\n",
    "knn_model = joblib.load('knn_model.pkl')\n",
    "knn_scaler = joblib.load('knn_scaler.pkl')\n",
    "path = \"./fall2.mp4\"\n",
    "cap = cv2.VideoCapture(path)\n",
    "# LINE Notify token\n",
    "token = 'UU7Ig7LUNtddRq0q3GROs2X0X72957PEVVw1qacyfEd'\n",
    "notice_time = datetime(1970, 1, 1) \n",
    "# 將信心值加入關鍵點座標\n",
    "def process_image(results):\n",
    "    r = results[0]\n",
    "    combined_results = []\n",
    "    for i in range(len(r.boxes)):\n",
    "        box_results = []\n",
    "        for  j  in range(17):\n",
    "            x, y = r.keypoints.xyn[i][j].numpy()\n",
    "            box_results.extend([x, y])\n",
    "            # confidence = r.keypoints.conf[i][j].item()  # Convert tensor to float\n",
    "        combined_results.append(box_results)\n",
    "    return combined_results\n",
    "# line傳送訊息\n",
    "def send_line_notify(token, image_path=None):\n",
    "    # Message to send\n",
    "    message = '有人跌倒了'\n",
    "\n",
    "    # HTTP headers and data\n",
    "    headers = { \"Authorization\": \"Bearer \" + token }\n",
    "    data = { 'message': message }\n",
    "    \n",
    "    # Send the POST request\n",
    "    if image_path:\n",
    "        # Open the image file in binary mode\n",
    "        with open(image_path, 'rb') as image_file:\n",
    "            image_data = {'imageFile': image_file}\n",
    "            response = requests.post(\"https://notify-api.line.me/api/notify\", headers=headers, data=data, files=image_data)\n",
    "    else:\n",
    "        response = requests.post(\"https://notify-api.line.me/api/notify\", headers=headers, data=data)\n",
    "\n",
    "    # Print the response\n",
    "    print(response.status_code)\n",
    "    print(response.text)\n",
    "# 開始影片偵測\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    current_time = datetime.now()\n",
    "    # Perform pose detection\n",
    "    results = model.track(frame, conf = 0.3) #偵測影片中人體關節點.track 可以將偵測到的人加上id\n",
    "    annotated_frame = results[0].plot() #.plot 將關鍵點畫到影片上\n",
    "    r = results[0] # r = 輸出結果 \n",
    "    # #印出 所有關鍵點的座標位置\n",
    "    # print(r.keypoints.xyn.numpy().reshape(-1, 2)) \n",
    "    # #印出 所有關鍵點的信心值\n",
    "    # print(r.keypoints.conf.numpy()) \n",
    "    #將所有關鍵點的位置與信心值丟入knn/svm/random forest/mlp 模型進行預測(0:沒跌倒/1:失衡/2:跌倒)\n",
    "    if len(results[0].boxes) >= 1:\n",
    "        data = np.array(process_image(results)) #  將資料轉成2d numpy array\n",
    "        data = knn_scaler.transform(data)\n",
    "        y_pred = knn_model.predict(data)\n",
    "        print(y_pred)\n",
    "        if y_pred[0] == 2:\n",
    "            fall_current_time = current_time\n",
    "            folder_name = 'Fall_img'\n",
    "            os.makedirs(folder_name, exist_ok=True)\n",
    "            time_text = fall_current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            cv2.imwrite(os.path.join(folder_name, fall_current_time.strftime(\"%Y-%m-%d_%H%M%S_fall.jpg\")), frame)\n",
    "            print(\"output save\")\n",
    "            #通知line，並將圖片送出\n",
    "            time_difference = notice_time - current_time\n",
    "            if notice_time == datetime(1970, 1, 1) or time_difference <= timedelta(seconds=1):\n",
    "                image_path = \"./Fall_img/\"+fall_current_time.strftime(\"%Y-%m-%d_%H%M%S_fall.jpg\")\n",
    "                send_line_notify(token, image_path=image_path)\n",
    "                notice_time = current_time + timedelta(seconds=11)\n",
    "\n",
    "\n",
    "    # 存進database\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    cv2.imshow('YOLOv8 Pose Detection', annotated_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b51db93-a0f5-40c9-a61e-3bec3a0b21af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from ultralytics import YOLO\n",
    "# Load YOLO model\n",
    "image_path = \"C:/Users/User/Desktop/Fall Detection/detect/detected_9281.jpg\"\n",
    "model = YOLO(\"yolov8n-pose.pt\")\n",
    "results = model(image_path)\n",
    "r = results[0] \n",
    "# by 照片人數去抓每個人的keypoints \n",
    "# 照片人數 = len(results[0].boxes)\n",
    "for i in range(len(results[0].boxes)):\n",
    "    # print(r.boxes.xywhn[i])\n",
    "    print(r.keypoints.conf[i]) # keypoint共有17個點,每個點yolo偵測到會給一個信心值\n",
    "    print(r.keypoints.xyn[i]) # keypoint共有17個點,yolo偵測到的x,y座標並做標準化\n",
    "    print(\"-----------------\")\n",
    "\n",
    "# Initialize a list to store the combined (x, y, confidence) tuples\n",
    "combined_results = []\n",
    "\n",
    "# Iterate over each keypoint\n",
    "for i in range(len(r.keypoints.xyn)):\n",
    "    for  j  in range(17):\n",
    "        x, y = r.keypoints.xyn[i][j].numpy() # Convert tensor to numpy\n",
    "        confidence = r.keypoints.conf[i][j].item()  # Convert tensor to float\n",
    "        combined_results.append((x, y, confidence))\n",
    "print(combined_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc31260-1de0-4449-824c-ed700783de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "# 圖片偵測存檔範例\n",
    "save_dir = \"C:/Users/leo86/Desktop/fall_dataset/processed_images/\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1, 209):\n",
    "    image_path = f\"C:/Users/leo86/Desktop/fall_dataset/images/train/fall{i:03d}.jpg\"\n",
    "    results = model.track(image_path, )\n",
    "    r = results[0]\n",
    "    im_array = r.plot()\n",
    "    im = Image.fromarray(im_array[..., ::-1])\n",
    "    save_path = os.path.join(save_dir, f\"fall{i:03d}.jpg\")\n",
    "    im.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaff618-7d1e-44b3-b8e5-492a9f68aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "# 圖片偵測存檔範例\n",
    "save_dir = \"C:/Users/leo86/Desktop/fall_dataset/processed_images/\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1, 167):\n",
    "    image_path = f\"C:/Users/leo86/Desktop/fall_dataset/images/train/not fallen{i:03d}.jpg\"\n",
    "    results = model.track(image_path, )\n",
    "    r = results[0]\n",
    "    im_array = r.plot()\n",
    "    im = Image.fromarray(im_array[..., ::-1])\n",
    "    save_path = os.path.join(save_dir, f\"not fallen{i:03d}.jpg\")\n",
    "    im.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf62563-8d32-4a43-bda1-f07cd6c8c4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = \"C:/Users/leo86/Desktop/fall_dataset/processed_images/\"\n",
    "\n",
    "missing_files = []\n",
    "\n",
    "for i in range(1, 209):\n",
    "    filename = os.path.join(directory, f\"fall{i:03d}.jpg\")\n",
    "    if not os.path.exists(filename):\n",
    "        missing_files.append(i)\n",
    "\n",
    "if missing_files:\n",
    "    print(\"Missing files:\")\n",
    "    print(missing_files)\n",
    "else:\n",
    "    print(\"All files exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a548b60-e922-4247-a32a-ee0ac11b6ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{\"status\":200,\"message\":\"ok\"}\n"
     ]
    }
   ],
   "source": [
    "    token = '6quBdcwBnxIbx1XjD8GT1InUIoAn0qmsHKxm8MmWPKC'\n",
    "    # Message to send\n",
    "    message = '有人跌倒了'\n",
    "\n",
    "    # HTTP headers and data\n",
    "    headers = { \"Authorization\": \"Bearer \" + token }\n",
    "    data = { 'message': message }\n",
    "\n",
    "    # Send the POST request\n",
    "    response = requests.post(\"https://notify-api.line.me/api/notify\", headers=headers, data=data)\n",
    "\n",
    "    # Print the response\n",
    "    print(response.status_code)\n",
    "    print(response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
